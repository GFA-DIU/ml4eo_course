{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtLfGAoaDL50"
   },
   "source": [
    "# EXERCISE 6.2: Crop Yield Estimation using Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "**Use of Google Earth Engine with US geodata to train a CNN in pytorch to predict crop yield Crop yield prediction**\n",
    "\n",
    "In this exercise, we will use data extracted from the popular EO Google Earth Engine (GEE) to access do crop yield estimation using the popular Deep Learning Library Pytorch. We will see how to\n",
    "\n",
    "1. Create a CNN model in Pytorch\n",
    "2. Train a Pytorch Model\n",
    "2. Evaluate a Pytorch model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1I7gpcxCmMhH"
   },
   "outputs": [],
   "source": [
    "!pip install geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2avqGxA3dRhy"
   },
   "source": [
    "## Setup\n",
    "Before working on this Exercise setup a GCP project with GEE and Google Drive APIs enabled by following the instructions given at https://docs.google.com/document/d/13SKLn_mqhlaRc1gElr4kmBrkw6KZPeqDDW3AjcTr8YY/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKIdst_KLXpY"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60e4I4Bmcffh"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "import traceback\n",
    "import urllib\n",
    "import folium\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwLqnhZBHw7l"
   },
   "source": [
    "## Setup Your Google Earth Engine Credentials\n",
    "Upload the `.private-key.json` you created while setting up GEE to the current runtime. Click Files > Upload to Session storage on the left pane in this notebook to upload. <br/>\n",
    "Replace the service account in the code below with your Google Cloud project service account email. It should be of the format <br/>`<id>@ml4eo-<some_number>.iam.gserviceaccount.com`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-7JYiydcsmH"
   },
   "outputs": [],
   "source": [
    "service_account = 'ml4eo-service@ml4eo-383508.iam.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, '.private-key.json')\n",
    "ee.Initialize(credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ky3ucjtgM8o"
   },
   "source": [
    "## <font color=orange>Discussion:</font>\n",
    "Before we start:\n",
    "Is crop yield estimation a classification or a regression task? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y11xyZXzMOaT"
   },
   "source": [
    "# Getting the Data\n",
    "The satellite data we will use is exported from the Moderate Resolution Imaging Spectroradiometer (MODIS) MODIS/MOD09A1 dataset. \n",
    "The input data we use include remote sensing data on surface reflectance, land surface temperature, and land cover type derived from the MODIS satellite, which are available worldwide. \n",
    "Specifically, the following datasets are used:\n",
    "\n",
    "\n",
    "1. **MOD09A1: Surface Reflectance**\n",
    "    \"An estimate of the surface spectral reflectance of Terra MODIS bands 1 through 7\".\n",
    "\n",
    "    Basically, an 'image' of the county as seen from the satellite.\n",
    "    \n",
    "2. **MCD12Q1: Land Cover Type**\n",
    "    Labels the data according to one of five global land cover classification systems. This is used as a mask, because we only want to consider pixels associated with farmland.\n",
    "3. **MYD11A2: Aqua/Land Surface Temperature**\n",
    "    Two more bands which can be used as input data to our models.\n",
    "\n",
    "The yield data is obtained from the USDA website, which measures soybean yields in bushels per acre. The data can be found at the following [link](https://fusiontables.google.com/data?docid=1S4EB6319wWW2sWQDPhDvmSBIVrD3iEmCLYB7nMM#rows:id=1).\n",
    "\n",
    "For this exercise, instead of having you export the satellite data yourself we will give you an exported, and preprocessed data that you can directly use for training. For anyone interested, we will supply a separate notebook that shows how the data was downloaded and preprocessed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_4ecOQvirg3"
   },
   "source": [
    "A file named `histogram_all_full.npz` which contains the preprocessed data has been shared with you.  \n",
    "Before you proceed make sure you have added the shared file to your drive by right clicking on it clicking \"Add shortcut to drive\". If you place it at a different location, ensure the path used below is the right one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g51s3Lgmfubr"
   },
   "source": [
    "The file `histogram_all_full.npz` contains five fields and 10,876 records.\n",
    "Here is a description of the five fields.\n",
    "1. output_image: An array that contains preprocessed satellite data as nine 32x32 images\n",
    "2. output_locations: An array that contains coordinates of each data point\n",
    "3. output_yield: An array that contains the yield obtained from the USDA data for each location (data point)\n",
    "4. output_year: An array that contains the year the yield was obtained at and the satellite data was captured.\n",
    "5. output_indices: An array that contains a pair of integers that uniquely identify each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfE2-TqZQM8b"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "with np.load(\"/content/drive/MyDrive/histogram_all_full.npz\") as hist:\n",
    "    images = hist[\"output_image\"]\n",
    "    locations = hist[\"output_locations\"]\n",
    "    yields = hist[\"output_yield\"]\n",
    "    years = hist[\"output_year\"]\n",
    "    indices = hist[\"output_index\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_QXi8k6kz2t"
   },
   "source": [
    "## Exploring the Dataset\n",
    "We know that one of the first steps in any ML task is data exploration.\n",
    "We will inspect trends and distribution of the target variable (yield) using many of the methods you studied in Module 5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cX0WBanWSYYI"
   },
   "outputs": [],
   "source": [
    "print(f\"Shape of images {images.shape}\")\n",
    "print(f\"Shape of locations {locations.shape}\")\n",
    "print(f\"Shape of yields {yields.shape}\")\n",
    "print(f\"Shape of years {years.shape}\")\n",
    "print(f\"Shape of indices {indices.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLGoFBxsAyQh"
   },
   "source": [
    "To make the exploration easier let's put the years and yields to a Pandas dataframe. We will leave out the other fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25UOcgQ0AP7g"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'year': years, 'yield': yields,})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if833BhJqEmE"
   },
   "source": [
    "Let's see how many years of data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5saTHjIJp28o"
   },
   "outputs": [],
   "source": [
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOJDB0OmyImw"
   },
   "source": [
    "## Yield Distribution\n",
    "Let's see what kind of yield distribution we have for the year 2003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnDY5BwY7NwU"
   },
   "outputs": [],
   "source": [
    "# Filter and keep the yield values that belong for the year 2003\n",
    "yields_2003 = yields[years==2003]\n",
    "\n",
    "# Compute the mean\n",
    "mean = yields_2003.mean()\n",
    "\n",
    "# Compute the mean\n",
    "median = np.median(yields_2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0pctIS5qT6K"
   },
   "outputs": [],
   "source": [
    "plt.hist(yields_2003, density=True)\n",
    "plt.plot([mean, mean], [0, 0.06], 'r')\n",
    "plt.plot([median, median], [0, 0.06], 'k')\n",
    "plt.xlabel('Yield (bushels per acre)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.ylim([0, 0.06])\n",
    "plt.legend(['Mean', 'Median'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr6LhIBUGqgv"
   },
   "source": [
    "## Question 6.2.1\n",
    "Show the distribution of yield for the year 2011. Indicate the mean and median as vertical lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P11tUXERHK-Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xR2tfFDjBd1q"
   },
   "source": [
    "Let's now visualize how the average yield changes through the years 2003 - 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dimR7lEkBdOK"
   },
   "outputs": [],
   "source": [
    "# Filter the data for years 2003 - 2011 (inclusive)\n",
    "data_03_11 = df[df['year'] <= 2011]\n",
    "# Compute the trend of means\n",
    "means = data_03_11.groupby(by=['year']).mean()\n",
    "means.reset_index(inplace=True)  # Get rid of multilevel index\n",
    "\n",
    "plt.plot(means['year'], means['yield'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Yield (bushels/acre)')\n",
    "plt.ylim([0, 50])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VNr0TDFEzNK"
   },
   "source": [
    "## <font color=orange>Discussion:</font>\n",
    "What trend do you see as the year increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UKxprfN_cKg"
   },
   "source": [
    "## Question 6.2.2\n",
    "Plot the trend of the median yield through the years 2003 - 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqykGKPFFHYD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8CkCclPGjRP"
   },
   "source": [
    "### Visualize the Yield as a Function of Location\n",
    "Above we have studied the temporal distribution of yield (how yield changes across time), now let's visualize the spatial distribution of yield (how yield varies over a given area) as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5MlOq87t77v"
   },
   "outputs": [],
   "source": [
    "# Ensure each location is used once in center computation\n",
    "unique_locations = np.unique(locations, axis=0)\n",
    "\n",
    "# compute center\n",
    "center = unique_locations.mean(axis=0)\n",
    "center = ee.Geometry.Point([center[0], center[1]])\n",
    "print(center.getInfo())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFC33wQmLyrL"
   },
   "source": [
    "Let's visualize the yields for the year 2003 as a heatmap on a GEE map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8nkS7BbLx41"
   },
   "outputs": [],
   "source": [
    "# Filter the locations\n",
    "locations_2003 = locations[years == 2003]\n",
    "yields_2003 = yields[years == 2003]\n",
    "\n",
    "# Convert the set of locations to GEE points\n",
    "gee_points = [ee.Geometry.Point(float(loc[0]), float(loc[1])) for loc in locations_2003]\n",
    "\n",
    "# Make a feature collection out of the set of GEE points\n",
    "points = ee.FeatureCollection(\n",
    "    [ee.Feature(pt, {'key': f\"loc {i}\", \"yield\": yields_2003[i]}) for i, pt in enumerate(gee_points)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB-3xiOpPawW"
   },
   "source": [
    "Let's write a function that displays the yield as a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9bK-aS0OFHC"
   },
   "outputs": [],
   "source": [
    "def heatmap(points, radius=20):\n",
    "    ptImg = points.reduceToImage(['yield'], ee.Reducer.first()).unmask(0)\n",
    "    kernel = ee.Kernel.circle(radius).add(ee.Kernel.gaussian(radius * 2, radius/2))\n",
    "    result = ptImg.convolve(kernel)\n",
    "    return result.updateMask(result.neq(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bWLIPY5PfMS"
   },
   "outputs": [],
   "source": [
    "heatmapImg = heatmap(points, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRimvggetkLW"
   },
   "outputs": [],
   "source": [
    "heatmapVis= {\"palette\":['lightgreen', 'green', 'yellow', '#880000', 'red']}\n",
    "\n",
    "map1 = geemap.Map()\n",
    "map1.centerObject(center, 6)\n",
    "map1.addLayer(heatmapImg, heatmapVis, \"heatmap\")\n",
    "map1.addLayerControl()\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE4-mMXnVFvK"
   },
   "source": [
    "To ensure our model has predictive power for future yields we will train the model for all years preceeding a given year and evaluate it on the given year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGlGteyZUKWa"
   },
   "outputs": [],
   "source": [
    "# Choose years for evaluation\n",
    "pred_years = range(2012, 2016)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGBSgisIV8JW"
   },
   "source": [
    "Since we will be using deep neural networks for this task it is better if we train and evaluate on a GPU. Colaboratory contains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blEdxjXjcigz"
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAyQjYCwhI71"
   },
   "source": [
    "## Image Standardization\n",
    "We will whiten all images by ensuring the mean of the images is zero. The following function does that.\n",
    "\n",
    "The mean is computed on the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ovma5Rz4XJU0"
   },
   "outputs": [],
   "source": [
    "def normalize_images(train_images, val_images):\n",
    "    mean = np.mean(train_images, axis=(0, 2, 3))\n",
    "\n",
    "    train_images = (train_images.transpose(0, 2, 3, 1) - mean).transpose(0, 3, 1, 2)\n",
    "    val_images = (val_images.transpose(0, 2, 3, 1) - mean).transpose(0, 3, 1, 2)\n",
    "\n",
    "    return train_images, val_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWe4MhI8lewV"
   },
   "source": [
    "## Deep Learning with Pytorch\n",
    "PyTorch is an open source machine learning framework that allows you to write your own neural networks and optimize them efficiently. However, PyTorch is not the only framework of its kind. Alternatives to PyTorch include TensorFlow, JAX and Caffe.\n",
    "\n",
    "Pytorch is well established, has a huge developer community (originally developed by Facebook), is very flexible and especially used in research. Many current papers publish their code in PyTorch, and thus it is good to be familiar with PyTorch as well. Meanwhile, TensorFlow (developed by Google) is usually known for being a production-grade deep learning library. Still, if you know one machine learning framework in depth, it is very easy to learn another one because many of them use the same concepts and ideas. For instance, TensorFlow’s version 2 was heavily inspired by the most popular features of PyTorch, making the frameworks even more similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1u-SmLlUNbnA"
   },
   "source": [
    "### Training Neural Networks\n",
    "A typical training procedure for a neural network is as follows:\n",
    "<ul class=\"simple\">\n",
    "<li><p>Define the neural network that has some learnable parameters (or\n",
    "weights)</p></li>\n",
    "<li><p>Iterate over a dataset of inputs</p></li>\n",
    "<li><p>Process input through the network</p></li>\n",
    "<li><p>Compute the loss (how far is the output from being correct)</p></li>\n",
    "<li><p>Propagate gradients back into the network’s parameters</p></li>\n",
    "<li><p>Update the weights of the network, typically using a simple update rule:\n",
    "<code class=\"docutils literal notranslate\"><span class=\"pre\">weight</span> <span class=\"pre\">=</span> <span class=\"pre\">weight</span> <span class=\"pre\">-</span> <span class=\"pre\">learning_rate</span> <span class=\"pre\">*</span> <span class=\"pre\">gradient</span></code></p></li>\n",
    "</ul>\n",
    "In Pytorch, the different the steps above are accomplished by instantiating the following classes:\n",
    "<ul class=\"simple\">\n",
    "<li><p>Define the neural network that has some learnable parameters (or\n",
    "weights)----> Create a sub-class of `torch.nn.Module`</p></li>\n",
    "<li><p>Iterate over a dataset of inputs ---> `torch.utils.data.Dataset` and `torch.utils.data.Dataloader`</p></li>\n",
    "<li><p>Process input through the network---> calling the `forward` method of the `torch.nn.Module` sub-class you instantiated</p></li>\n",
    "<li><p>Compute the loss (how far is the output from being correct) ---> Creating an instance of `torch.nn.Module` and passing the outputs of your model and labels to it</p></li>\n",
    "<li><p>Propagate gradients back into the network’s parameters---> Calling the `backward` method on the loss computed by the step above </p></li>\n",
    "<li><p>Update the weights of the network, typically using a simple update rule:---> Calling the `step` method on a sub-class of `torch.optim.Optimizer` you instantiated\n",
    "</ul>\n",
    "\n",
    "It is all right if some of the steps above are unclear as we will explore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_y4BgaBODVk"
   },
   "source": [
    "## The Neural Network Model\n",
    "We will use a Convolutional Neural Network for this problem. \n",
    "\n",
    "A Convolutional Neural Netowrk (CNN) is a Deep Learning algorithm that can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image, and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms.\n",
    "\n",
    "The CNN we will use is based on the paper https://cs.stanford.edu/~ermon/papers/cropyield_AAAI17.pdf\n",
    "\n",
    "This is what the model looks like.\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFn4k79PWafg"
   },
   "source": [
    "In the next section we provide a class called `Conv2dSamePadding` which is a utility class that allows as to have CNN layers that return output that has the same size as the input. For example if a 32x32 image is fed to a given `Conv2dSamePadding` layer the output will also have a dimension of 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UfMpk7eiFgX"
   },
   "outputs": [],
   "source": [
    "class Conv2dSamePadding(nn.Conv2d):\n",
    "    def forward(self, input):\n",
    "        return convding(nn.Conv2d)\n",
    "    def forward(self, input):\n",
    "        return conv2d_same_padding(\n",
    "            input, self.weight, self.bias, self.stride, self.dilation, self.groups\n",
    "        )\n",
    "\n",
    "\n",
    "def conv2d_same_padding(input, weight, bias=None, stride=1, dilation=1, groups=1):\n",
    "    # stride and dilation are expected to be tuples.\n",
    "\n",
    "    # first, we'll figure out how much padding is necessary for the rows\n",
    "    input_rows = input.size(2)\n",
    "    filter_rows = weight.size(2)\n",
    "    effective_filter_size_rows = (filter_rows - 1) * dilation[0] + 1\n",
    "    out_rows = (input_rows + stride[0] - 1) // stride[0]\n",
    "    padding_rows = max(\n",
    "        0, (out_rows - 1) * stride[0] + effective_filter_size_rows - input_rows\n",
    "    )\n",
    "    rows_odd = padding_rows % 2 != 0\n",
    "\n",
    "    # same for columns\n",
    "    input_cols = input.size(3)\n",
    "    filter_cols = weight.size(3)\n",
    "    effective_filter_size_cols = (filter_cols - 1) * dilation[1] + 1\n",
    "    out_cols = (input_cols + stride[1] - 1) // stride[1]\n",
    "    padding_cols = max(\n",
    "        0, (out_cols - 1) * stride[1] + effective_filter_size_cols - input_cols\n",
    "    )\n",
    "    cols_odd = padding_cols % 2 != 0\n",
    "\n",
    "    if rows_odd or cols_odd:\n",
    "        input = F.pad(input, [0, int(cols_odd), 0, int(rows_odd)])\n",
    "\n",
    "    return F.conv2d(\n",
    "        input,\n",
    "        weight,\n",
    "        bias,\n",
    "        stride,\n",
    "        padding=(padding_rows // 2, padding_cols // 2),\n",
    "        dilation=dilation,\n",
    "        groups=groups,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzakDlt9XKUL"
   },
   "source": [
    "### Define the Model\n",
    "The following class contains 8 layers (5 convolutional layers + 2 Linear layers). Each convolutional layer is followed by a batch normalization unit, a Rectified Linear Unit, and a dropout. \n",
    "\n",
    "This network takes an image with a dimension of 32x32, and 9 channels. That is, the expected input is 9x32x32. Note that Pytorch Conv2d expects the channels to be the first axis by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JkD7aKVH3O9"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define layer 1\n",
    "        self.conv1 = Conv2dSamePadding(9, 128, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.bn1 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "        # Define layer 2\n",
    "        self.conv2 = Conv2dSamePadding(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
    "        self.bn2 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "        # Define layer 3\n",
    "        self.conv3 = Conv2dSamePadding(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.bn3 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "        # Define layer 4\n",
    "        self.conv4 = Conv2dSamePadding(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
    "        self.bn4 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.drop4 = nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "        # Define layer 5\n",
    "        self.conv5 = Conv2dSamePadding(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.bn5 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.drop5 = nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "        # Define layer 6\n",
    "        self.conv6 = Conv2dSamePadding(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
    "        self.bn6 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.drop6 = nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=8192, out_features=2048, bias=True)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.drop2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.drop3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        x = self.drop4(self.relu4(self.bn4(self.conv4(x))))\n",
    "        x = self.drop5(self.relu5(self.bn5(self.conv5(x))))\n",
    "        x = self.drop6(self.relu6(self.bn6(self.conv6(x))))\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = self.relu7(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "972ELwWGZiii"
   },
   "source": [
    "## Training\n",
    "In this training loop we randomly split the data into two sets (training and validation), create a data loader, an optimizer, and a loss function. Then, we use the above objects and our model to train it. The function is thouroughly commented please read it to understand what this function is doing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HjjqfvmZdY_"
   },
   "outputs": [],
   "source": [
    "def train(model, train_data, train_steps,batch_size, lr):\n",
    "    # Determine the number of samples we have\n",
    "    total_size = train_data[0].shape[0]\n",
    "    # Use 10% of the data for validation\n",
    "    val_size = total_size // 10\n",
    "    # Keep the rest for training\n",
    "    train_size = total_size - val_size\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    train_dataset, val_dataset = random_split(\n",
    "            TensorDataset(train_data[0], train_data[1]), (train_size, val_size)\n",
    "    )\n",
    "    # Create the training data loader\n",
    "    train_dataloader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    # Create the validation data loader\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Create an optimizer that will be used to update the model\n",
    "    optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "    )\n",
    "    # Determine how many times the model should see each data point in the training data\n",
    "    num_epochs = int(train_steps / (total_size / batch_size))\n",
    "    print(f\"Training for {num_epochs} epochs\")\n",
    "\n",
    "    # Instantiate dictionaries to keep scores\n",
    "    train_scores = defaultdict(list)\n",
    "    val_scores = defaultdict(list)\n",
    "\n",
    "    step_number = 0\n",
    "    min_loss = np.inf\n",
    "\n",
    "    # Initialize a variable to save the best weights (weights that give the best results)\n",
    "    best_state = model.state_dict()\n",
    "\n",
    "    # Define a new loss function (MSE Loss is widely used for regression tasks)\n",
    "    criterion = nn.MSELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Switch the model to training mode \n",
    "        model.train()\n",
    "\n",
    "        # running train and val scores are only for printing out\n",
    "        # information\n",
    "        running_train_scores = defaultdict(list)\n",
    "\n",
    "        # Iterate over the dataset\n",
    "        for train_x, train_y in tqdm(train_dataloader):\n",
    "            # Clear the previous gradients accumulated from the model\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Pass the training data to the model\n",
    "            pred_y = model(train_x.to(device))\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(pred_y, train_y.to(device))\n",
    "\n",
    "            # Propagate gradients through the network\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Keep the scores\n",
    "            train_scores[\"loss\"].append(loss.item())\n",
    "\n",
    "            step_number += 1\n",
    "\n",
    "            # Decrease the learning rate after 4000 and 20000 steps\n",
    "            if step_number in [4000, 20000]:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group[\"lr\"] /= 10\n",
    "\n",
    "        train_output_strings = []\n",
    "        for key, val in running_train_scores.items():\n",
    "            train_output_strings.append(\n",
    "                \"{}: {}\".format(key, round(np.array(val).mean(), 5))\n",
    "            )\n",
    "\n",
    "        running_val_scores = defaultdict(list)\n",
    "        # Switch the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Iterate over the validation dataset\n",
    "            for (val_x, val_y) in tqdm(val_dataloader):\n",
    "                # Pass the validation sample to the model\n",
    "                val_pred_y = model(val_x.to(device))\n",
    "\n",
    "                # Compute the loss\n",
    "                val_loss = criterion(val_pred_y, val_y.to(device))\n",
    "\n",
    "                # Save the computed loss\n",
    "                val_scores[\"loss\"].append(val_loss.item())\n",
    "\n",
    "        val_output_strings = []\n",
    "        for key, val in running_val_scores.items():\n",
    "            val_output_strings.append(\n",
    "                \"{}: {}\".format(key, round(np.array(val).mean(), 5))\n",
    "            )\n",
    "\n",
    "        print(\"TRAINING: {}\".format(\", \".join(train_output_strings)))\n",
    "        print(\"VALIDATION: {}\".format(\", \".join(val_output_strings)))\n",
    "\n",
    "        # Compute the mean validation loss (over the validation samples)\n",
    "        epoch_val_loss = np.array(running_val_scores[\"loss\"]).mean()\n",
    "\n",
    "        # If the validation loss is smaller than the historic minimum save the current weights as the best weights\n",
    "        if epoch_val_loss < min_loss:\n",
    "            best_state = model.state_dict()\n",
    "            min_loss = epoch_val_loss\n",
    "    # Return the best model\n",
    "    model.load_state_dict(best_state)\n",
    "    return train_scores, val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qpTHDuHjAb9"
   },
   "source": [
    "### Evaluation\n",
    "Now that we have training function let's write a function that evaluates the model on the training set and the test set. This function will iterate over the training and test datasets to compute the output of each sample in each set. Read the comments to understand what the function is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LaU8dFudSAq"
   },
   "outputs": [],
   "source": [
    "def predict(model, train_data, test_data, batch_size):\n",
    "    train_images, train_yields, train_locations, train_indices, train_years = train_data\n",
    "\n",
    "    # Create a dataset of training samples\n",
    "    train_dataset = TensorDataset(\n",
    "        train_images, train_yields, train_locations, train_indices, train_years\n",
    "    )\n",
    "\n",
    "    test_images, test_yields, test_locations, test_indices, test_years = test_data\n",
    "\n",
    "    # Create a dataset of test samples\n",
    "    test_dataset = TensorDataset(\n",
    "        test_images, test_yields, test_locations, test_indices, test_years\n",
    "    )\n",
    "\n",
    "    # Create a train and test data loaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the training dataset\n",
    "        for train_im, train_yield, train_loc, train_idx, train_year in tqdm(\n",
    "            train_dataloader):\n",
    "            # Pass the sample to the model and compute the output\n",
    "            model_output = model(train_im.to(device))\n",
    "            pred = model_output\n",
    "\n",
    "            # Save the results\n",
    "            results[\"train_pred\"].extend(pred.squeeze(1).tolist())\n",
    "            results[\"train_real\"].extend(train_yield.squeeze(1).tolist())\n",
    "            results[\"train_loc\"].append(train_loc.numpy())\n",
    "            results[\"train_indices\"].append(train_idx.numpy())\n",
    "            results[\"train_years\"].extend(train_year.tolist())\n",
    "\n",
    "        # Iterate over the test dataset\n",
    "        for test_im, test_yield, test_loc, test_idx, test_year in tqdm(\n",
    "            test_dataloader\n",
    "        ):\n",
    "            # Compute the output\n",
    "            model_output = model(test_im.to(device))\n",
    "            pred = model_output\n",
    "\n",
    "            # Save the output\n",
    "            results[\"test_pred\"].extend(pred.squeeze(1).tolist())\n",
    "            results[\"test_real\"].extend(test_yield.squeeze(1).tolist())\n",
    "            results[\"test_loc\"].append(test_loc.numpy())\n",
    "            results[\"test_indices\"].append(test_idx.numpy())\n",
    "            results[\"test_years\"].extend(test_year.tolist())\n",
    "\n",
    "    for key in results:\n",
    "        if key in [\n",
    "            \"train_feat\",\n",
    "            \"test_feat\",\n",
    "            \"train_loc\",\n",
    "            \"test_loc\",\n",
    "            \"train_indices\",\n",
    "            \"test_indices\",\n",
    "            \"test_pred\",\n",
    "            \"test_real\",\n",
    "        ]:\n",
    "            results[key] = np.array(results[key])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI73a8iDkYwB"
   },
   "source": [
    "## Running the Training and Evaluation\n",
    "Let's say we want to predict the yield for the year 2012. What we should do is train on data available for the years 2003 - 2011 and evaluate the model on the data for the year 2012. That way we can ensure we have trained a causal model (a model that has predictive power without seeing future data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq17dGmnWhpK"
   },
   "outputs": [],
   "source": [
    "def run_one_year(model, predict_year, time, train_steps, batch_size, lr):\n",
    "    # Use the data for years precedding `predict_year` as training data\n",
    "    train_idx = np.nonzero(years < predict_year)[0]\n",
    "    # Use the data for the year `predict_year` as evaluation (testing) data\n",
    "    test_idx = np.nonzero(years == predict_year)[0]\n",
    "\n",
    "    train_images, test_images = normalize_images(images[train_idx], \n",
    "                                                  images[test_idx])\n",
    "    \n",
    "    # Return a training data tuple containing images, yields, locations, indices, and years\n",
    "    train_data = (\n",
    "        torch.as_tensor(\n",
    "                    train_images[:, :, :time, :], device=device\n",
    "                ).float(),\n",
    "        torch.as_tensor(yields[train_idx], device=device).float().unsqueeze(1),\n",
    "        torch.as_tensor(locations[train_idx]),\n",
    "        torch.as_tensor(indices[train_idx]),\n",
    "        torch.as_tensor(years[train_idx]),                \n",
    "    )\n",
    "\n",
    "    # Return a test data tuple containing images, yields, locations, indices, and years\n",
    "    test_data = (\n",
    "            torch.as_tensor(\n",
    "                test_images[:, :, :time, :], device=device\n",
    "            ).float(),\n",
    "            torch.as_tensor(yields[test_idx], device=device).float().unsqueeze(1),\n",
    "            torch.as_tensor(locations[test_idx]),\n",
    "            torch.as_tensor(indices[test_idx]),\n",
    "            torch.as_tensor(years[test_idx]),\n",
    "    )\n",
    "\n",
    "    # Call the training function to train the model\n",
    "    train_scores, val_scores = train(model, train_data, train_steps, batch_size, lr)\n",
    "\n",
    "    # Call the evaluation function to evaluate the model on train and test sets\n",
    "    results = predict(model, train_data, test_data, batch_size)\n",
    "    \n",
    "    model_information = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"val_loss\": val_scores[\"loss\"],\n",
    "            \"train_loss\": train_scores[\"loss\"],\n",
    "    }\n",
    "    for key in results:\n",
    "        model_information[key] = results[key]\n",
    "    \n",
    "    true, pred =  model_information[\"test_real\"], model_information[\"test_pred\"]\n",
    "    \n",
    "    # Compute the RMSE and ME\n",
    "    rmse = np.sqrt(np.mean((true - pred) ** 2))\n",
    "    me = np.mean(true - pred)\n",
    "    \n",
    "    return rmse, me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XVhY3DipmhE"
   },
   "source": [
    "## Running the Training/Evaluation\n",
    "We will now use the following function that uses the functions above to run the entire process of training.\n",
    "\n",
    "This function run training and evaluation of the model for each year in the variable `pred_years` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeQmMuxJUbOM"
   },
   "outputs": [],
   "source": [
    "def run(model, batch_size=32, learning_rate=1e-3, weight_decay=0,\n",
    "        train_steps=2500):\n",
    "    years_list, run_numbers, rmse_list, me_list, times_list = [], [], [], [], []\n",
    "    times = [32]\n",
    "    for pred_year in pred_years:\n",
    "        for time in times:\n",
    "            results = run_one_year(model, pred_year, time, train_steps, \n",
    "                                   batch_size,learning_rate)\n",
    "            years_list.append(pred_year)\n",
    "            times_list.append(time)\n",
    "            rmse, me = results\n",
    "            rmse_list.append(rmse)\n",
    "            me_list.append(me)\n",
    "    data = {\n",
    "        \"year\": years_list,\n",
    "        \"time_idx\": times_list,\n",
    "        \"RMSE\": rmse_list,\n",
    "        \"ME\": me_list,\n",
    "    }\n",
    "    results_df = pd.DataFrame(data=data)\n",
    "    results_df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEtkW65ghl_F"
   },
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFGpPqfIr2vy"
   },
   "source": [
    "### Sanity Check\n",
    "To ensure our model works as expected let's pass one of the images as tensor input and examine the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9Y4uxwzSf8T"
   },
   "outputs": [],
   "source": [
    "tensor_input = torch.as_tensor(images[0]).unsqueeze(0).float().to(device)\n",
    "print(\"Input shape is:\", tensor_input.shape)\n",
    "out = model(tensor_input)\n",
    "\n",
    "print(\"Output is: \", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU35GUPUyX6a"
   },
   "source": [
    "## Question 6.2.3\n",
    "Pass the model an image of zeros and print the output you get.\n",
    "Don't remove the `torch.seed(42)` write your solution under this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_KkNtEpsQ9k"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Answer\n",
    "tensor_input = \n",
    "out = \n",
    "\n",
    "print(\"Output is: \", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5efMpCSzWkS"
   },
   "source": [
    "## Question 6.2.4\n",
    "1. Run the cell above 5 times and log the result you get for the five runs.\n",
    "2. Comment out the line `torch.manual_seed(42)`, run the cell above 5 times, and log the results for the five runs.\n",
    "\n",
    "## <font color=orange>Discussion:</font>\n",
    "What did you observe from the above results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfPcF4bm0Cv5"
   },
   "source": [
    "## Run Training and Validation\n",
    "\n",
    "Let's now run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBxqcM4KywMU"
   },
   "outputs": [],
   "source": [
    "run(model, train_steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2zN7j_aCk2p"
   },
   "source": [
    "# Checking the Results\n",
    "Let's now load and inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Kgr0As41zUM"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmnCnKJcC5OZ"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "`# This is formatted as code`\n",
    "```\n",
    "\n",
    "## Question 6.2.5\n",
    "For which year did you get the best results? What was the value? Can you explain the results? Submit your Pandas Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mh6oOqptDYM-"
   },
   "source": [
    "## Question 6.2.6\n",
    "Run the model or 100,000 steps and submit your results dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSR-0NkgDf6L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
