{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtLfGAoaDL50"
      },
      "source": [
        "# EXERCISE 7.2: Deep Learning for Crop Yield Estimation - Experiment Tracking\n",
        "\n",
        "---\n",
        "\n",
        "**Use of Google Earth Engine with US geodata to train a CNN in pytorch to predict crop yield Crop yield prediction in a systematized experiment tracking environment employing WandB**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I7gpcxCmMhH"
      },
      "outputs": [],
      "source": [
        "!pip install geemap -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mX5KXuUpE9F"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2avqGxA3dRhy"
      },
      "source": [
        "## Setup\n",
        "Before working on this Exercise setup a GCP project with GEE and Google Drive APIs enabled by following the instructions given at https://docs.google.com/document/d/13SKLn_mqhlaRc1gElr4kmBrkw6KZPeqDDW3AjcTr8YY/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKIdst_KLXpY",
        "outputId": "320eb9e4-9911-4614-9fdf-94d2d30298ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60e4I4Bmcffh"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import os\n",
        "import traceback\n",
        "import urllib\n",
        "import folium\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import optimize\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import geemap\n",
        "import wandb\n",
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwLqnhZBHw7l"
      },
      "source": [
        "## Setup Your Google Earth Engine Credentials\n",
        "Upload the `.private-key.json` you created while setting up GEE to the current runtime. Click Files > Upload to Session storage on the left pane in this notebook to upload. <br/>\n",
        "Replace the service account in the code below with your Google Cloud project service account email. It should be of the format <br/>`<id>@ml4eo-<some_number>.iam.gserviceaccount.com`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-7JYiydcsmH"
      },
      "outputs": [],
      "source": [
        "service_account = 'ml4eo-service@ml4eo-383508.iam.gserviceaccount.com'\n",
        "credentials = ee.ServiceAccountCredentials(service_account, '.private-key.json')\n",
        "ee.Initialize(credentials)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ky3ucjtgM8o"
      },
      "source": [
        "# Discussion\n",
        "Before we start:\n",
        "Is crop yield estimation a classification or a regression task? Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYFpaW5rpJ6l"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfE2-TqZQM8b"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "with np.load(\"/content/drive/MyDrive/histogram_all_full.npz\") as hist:\n",
        "    images = hist[\"output_image\"]\n",
        "    locations = hist[\"output_locations\"]\n",
        "    yields = hist[\"output_yield\"]\n",
        "    years = hist[\"output_year\"]\n",
        "    indices = hist[\"output_index\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCWvyaQK4HVv"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAyQjYCwhI71"
      },
      "source": [
        "## Image Standardization\n",
        "We will whiten all images by ensuring the mean of the images is zero. The following function does that.\n",
        "\n",
        "The mean is computed on the training images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz7W-v-f4Gaj"
      },
      "outputs": [],
      "source": [
        "pred_years = [2012]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovma5Rz4XJU0"
      },
      "outputs": [],
      "source": [
        "def normalize_images(train_images, val_images):\n",
        "    mean = np.mean(train_images, axis=(0, 2, 3))\n",
        "\n",
        "    train_images = (train_images.transpose(0, 2, 3, 1) - mean).transpose(0, 3, 1, 2)\n",
        "    val_images = (val_images.transpose(0, 2, 3, 1) - mean).transpose(0, 3, 1, 2)\n",
        "\n",
        "    return train_images, val_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFn4k79PWafg"
      },
      "source": [
        "# Define the Config Dictionary for Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgNBvUrUpBOB"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'conv1': {\n",
        "        'in_chan': 9,\n",
        "        'out_chan': 128,\n",
        "        'stride': (1, 1),\n",
        "        'kernel_size': (3, 3),\n",
        "\n",
        "    },\n",
        "    'conv2': {\n",
        "        'in_chan': 128,\n",
        "        'out_chan': 256,\n",
        "        'stride': (2, 2),\n",
        "        'kernel_size': (3, 3),\n",
        "\n",
        "    },\n",
        "    'conv3': {\n",
        "        'in_chan': 256,\n",
        "        'out_chan': 256,\n",
        "        'stride': (1, 1),\n",
        "        'kernel_size': (3, 3),\n",
        "\n",
        "    },\n",
        "    'conv4': {\n",
        "        'in_chan': 256,\n",
        "        'out_chan': 512,\n",
        "        'stride': (2, 2),\n",
        "        'kernel_size': (3, 3),\n",
        "\n",
        "    },\n",
        "    'conv5': {\n",
        "        'in_chan': 512,\n",
        "        'out_chan': 512,\n",
        "        'stride': (1, 1),\n",
        "        'kernel_size': (3,3),\n",
        "    },\n",
        "    'conv6': {\n",
        "        'in_chan': 512,\n",
        "        'out_chan': 512,\n",
        "        'stride': (2, 2),\n",
        "        'kernel_size': (3, 3),\n",
        "\n",
        "    },\n",
        "    'fc1_in': 8192,\n",
        "    'fc1_out': 2048,\n",
        "    'fc2_out': 2,\n",
        "    'dropout_rate': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'train_steps': 25000,\n",
        "    'criterion': 'mse',\n",
        "    'optimizer': 'adam',\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UfMpk7eiFgX"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class Conv2dSamePadding(nn.Conv2d):\n",
        "    def forward(self, input):\n",
        "        return conv2d_same_padding(\n",
        "            input, self.weight, self.bias, self.stride, self.dilation, self.groups\n",
        "        )\n",
        "\n",
        "\n",
        "def conv2d_same_padding(input, weight, bias=None, stride=1, dilation=1, groups=1):\n",
        "    # stride and dilation are expected to be tuples.\n",
        "\n",
        "    # first, we'll figure out how much padding is necessary for the rows\n",
        "    input_rows = input.size(2)\n",
        "    filter_rows = weight.size(2)\n",
        "    effective_filter_size_rows = (filter_rows - 1) * dilation[0] + 1\n",
        "    out_rows = (input_rows + stride[0] - 1) // stride[0]\n",
        "    padding_rows = max(\n",
        "        0, (out_rows - 1) * stride[0] + effective_filter_size_rows - input_rows\n",
        "    )\n",
        "    rows_odd = padding_rows % 2 != 0\n",
        "\n",
        "    # same for columns\n",
        "    input_cols = input.size(3)\n",
        "    filter_cols = weight.size(3)\n",
        "    effective_filter_size_cols = (filter_cols - 1) * dilation[1] + 1\n",
        "    out_cols = (input_cols + stride[1] - 1) // stride[1]\n",
        "    padding_cols = max(\n",
        "        0, (out_cols - 1) * stride[1] + effective_filter_size_cols - input_cols\n",
        "    )\n",
        "    cols_odd = padding_cols % 2 != 0\n",
        "\n",
        "    if rows_odd or cols_odd:\n",
        "        input = F.pad(input, [0, int(cols_odd), 0, int(rows_odd)])\n",
        "\n",
        "    return F.conv2d(\n",
        "        input,\n",
        "        weight,\n",
        "        bias,\n",
        "        stride,\n",
        "        padding=(padding_rows // 2, padding_cols // 2),\n",
        "        dilation=dilation,\n",
        "        groups=groups,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rdt6V9izSnV"
      },
      "outputs": [],
      "source": [
        "wandb.init(project='DL_Crop_yield', config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzakDlt9XKUL"
      },
      "source": [
        "### Define the Model\n",
        "The following class contains 8 layers (5 convolutional layers + 2 Linear layers). Each convolutional layer is followed by a batch normalization unit, a Rectified Linear Unit, and a dropout.\n",
        "\n",
        "This network takes an image with a dimension of 32x32, and 9 channels. That is, the expected input is 9x32x32. Note that Pytorch Conv2d expects the channels to be the first axis by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JkD7aKVH3O9"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Define layer 1\n",
        "        self.conv1 = Conv2dSamePadding(config['conv1']['in_chan'],\n",
        "                                       config['conv1']['out_chan'],\n",
        "                                       kernel_size=config['conv1']['kernel_size'],\n",
        "                                       stride=config['conv1']['stride'])\n",
        "        self.bn1 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.drop1 = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        # Define layer 2\n",
        "        self.conv2 = Conv2dSamePadding(config['conv2']['in_chan'],\n",
        "                                       config['conv2']['out_chan'],\n",
        "                                       kernel_size=config['conv2']['kernel_size'],\n",
        "                                       stride=config['conv2']['stride'])\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.drop2 = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        # Define layer 3\n",
        "        self.conv3 = Conv2dSamePadding(config['conv3']['in_chan'],\n",
        "                                       config['conv3']['out_chan'],\n",
        "                                       kernel_size=config['conv3']['kernel_size'],\n",
        "                                       stride=config['conv3']['stride'])\n",
        "\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(256,\n",
        "                                  eps=1e-05,\n",
        "                                  momentum=0.1,\n",
        "                                  affine=True,\n",
        "                                  track_running_stats=True)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop3 = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        # Define layer 4\n",
        "        self.conv4 = Conv2dSamePadding(config['conv4']['in_chan'],\n",
        "                                       config['conv4']['out_chan'],\n",
        "                                       kernel_size=config['conv4']['kernel_size'],\n",
        "                                       stride=config['conv4']['stride'])\n",
        "\n",
        "        self.bn4 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.drop4 = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        # Define layer 5\n",
        "        self.conv5 = Conv2dSamePadding(config['conv5']['in_chan'],\n",
        "                                       config['conv5']['out_chan'],\n",
        "                                       kernel_size=config['conv5']['kernel_size'],\n",
        "                                       stride=config['conv5']['stride'])\n",
        "\n",
        "        self.bn5 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.drop5 = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        # Define layer 6\n",
        "        self.conv6 = Conv2dSamePadding(config['conv6']['in_chan'],\n",
        "                                       config['conv6']['out_chan'],\n",
        "                                       kernel_size=config['conv6']['kernel_size'],\n",
        "                                       stride=config['conv6']['stride'])\n",
        "\n",
        "        self.bn6 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu6 = nn.ReLU()\n",
        "        self.drop6 = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=8192, out_features=2048, bias=True)\n",
        "        self.relu7 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(in_features=2048, out_features=1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.drop1(self.relu1(self.bn1(self.conv1(x))))\n",
        "        x = self.drop2(self.relu2(self.bn2(self.conv2(x))))\n",
        "        x = self.drop3(self.relu3(self.bn3(self.conv3(x))))\n",
        "        x = self.drop4(self.relu4(self.bn4(self.conv4(x))))\n",
        "        x = self.drop5(self.relu5(self.bn5(self.conv5(x))))\n",
        "        x = self.drop6(self.relu6(self.bn6(self.conv6(x))))\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        x = self.relu7(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kYd7VPx_Nx"
      },
      "source": [
        "## Question 7.2.1\n",
        "Some hyperparameters of the model above are not controlled by the `config` dictionary. Please go up and update the model so that all of the models hyperparameters are taken from the `config` dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "972ELwWGZiii"
      },
      "source": [
        "## Training\n",
        "In this training loop we randomly split the data into two sets (training and validation), create a data loader, an optimizer, and a loss function. Then, we use the above objects and our model to train it. The function is thouroughly commented please read it to understand what this function is doing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HjjqfvmZdY_"
      },
      "outputs": [],
      "source": [
        "def train(model, train_data, train_steps,batch_size, lr):\n",
        "    # Determine the number of samples we have\n",
        "    total_size = train_data[0].shape[0]\n",
        "    # Use 10% of the data for validation\n",
        "    val_size = total_size // 10\n",
        "    # Keep the rest for training\n",
        "    train_size = total_size - val_size\n",
        "\n",
        "    # Split the dataset into training and validation sets\n",
        "    train_dataset, val_dataset = random_split(\n",
        "            TensorDataset(train_data[0], train_data[1]), (train_size, val_size)\n",
        "    )\n",
        "    # Create the training data loader\n",
        "    train_dataloader = DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    # Create the validation data loader\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Create an optimizer that will be used to update the model\n",
        "    if config['optimizer'] == 'adam':\n",
        "        optimizer = torch.optim.Adam(\n",
        "                model.parameters(),\n",
        "                lr=config['lr'],\n",
        "        )\n",
        "    # Determine how many times the model should see each data point in the training data\n",
        "    num_epochs = int(train_steps / (total_size / batch_size))\n",
        "    print(f\"Training for {num_epochs} epochs\")\n",
        "\n",
        "    # Instantiate dictionaries to keep scores\n",
        "    train_scores = defaultdict(list)\n",
        "    val_scores = defaultdict(list)\n",
        "\n",
        "    step_number = 0\n",
        "    min_loss = np.inf\n",
        "\n",
        "    # Initialize a variable to save the best weights (weights that give the best results)\n",
        "    best_state = model.state_dict()\n",
        "\n",
        "    # Define a new loss function (MSE Loss is widely used for regression tasks)\n",
        "    if config['criterion'] == 'mse':\n",
        "        criterion = nn.MSELoss()\n",
        "    for epoch in range(num_epochs):\n",
        "        # Switch the model to training mode\n",
        "        model.train()\n",
        "\n",
        "        # running train and val scores are only for printing out\n",
        "        # information\n",
        "        running_train_scores = defaultdict(list)\n",
        "\n",
        "        # Iterate over the dataset\n",
        "        for train_x, train_y in tqdm(train_dataloader):\n",
        "            # Clear the previous gradients accumulated from the model\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Pass the training data to the model\n",
        "            pred_y = model(train_x.to(device))\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(pred_y, train_y.to(device))\n",
        "\n",
        "            # Propagate gradients through the network\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Keep the scores\n",
        "            train_scores[\"loss\"].append(loss.item())\n",
        "\n",
        "            step_number += 1\n",
        "\n",
        "            # Decrease the learning rate after 4000 and 20000 steps\n",
        "            if step_number in [4000, 20000]:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group[\"lr\"] /= 10\n",
        "\n",
        "        train_output_strings = []\n",
        "        wandb_data = dict()\n",
        "        for key, val in running_train_scores.items():\n",
        "            wandb_data[key] = round(np.array(val).mean())\n",
        "            train_output_strings.append(\n",
        "                \"{}: {}\".format(key, round(np.array(val).mean(), 5))\n",
        "            )\n",
        "\n",
        "        running_val_scores = defaultdict(list)\n",
        "        # Switch the model to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Iterate over the validation dataset\n",
        "            for i, (val_x, val_y) in tqdm(enumerate(val_dataloader)):\n",
        "                # Pass the validation sample to the model\n",
        "                if i == 0:\n",
        "                    img = make_grid(val_x[:, :3, ...])\n",
        "                    wandb.log({\"img\": img})\n",
        "                val_pred_y = model(val_x.to(device))\n",
        "\n",
        "                # Compute the loss\n",
        "                val_loss = criterion(val_pred_y, val_y.to(device))\n",
        "\n",
        "                # Save the computed loss\n",
        "                val_scores[\"loss\"].append(val_loss.item())\n",
        "\n",
        "        val_output_strings = []\n",
        "        for key, val in running_val_scores.items():\n",
        "            wandb_data[key] = round(np.array(val).mean())\n",
        "            val_output_strings.append(\n",
        "                \"{}: {}\".format(key, round(np.array(val).mean(), 5))\n",
        "            )\n",
        "        print(\"TRAINING: {}\".format(\", \".join(train_output_strings)))\n",
        "        print(\"VALIDATION: {}\".format(\", \".join(val_output_strings)))\n",
        "\n",
        "        # Compute the mean validation loss (over the validation samples)\n",
        "        epoch_val_loss = np.array(running_val_scores[\"loss\"]).mean()\n",
        "        wandb_data['step'] = step_number\n",
        "        wandb_data['epoch_val_loss'] = epoch_val_loss\n",
        "        wandb.log(wandb_data)\n",
        "\n",
        "        # If the validation loss is smaller than the historic minimum save the current weights as the best weights\n",
        "        if epoch_val_loss < min_loss:\n",
        "            best_state = model.state_dict()\n",
        "            min_loss = epoch_val_loss\n",
        "    # Return the best model\n",
        "    model.load_state_dict(best_state)\n",
        "    return train_scores, val_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qpTHDuHjAb9"
      },
      "source": [
        "### Evaluation\n",
        "Now that we have training function let's write a function that evaluates the model on the training set and the test set. This function will iterate over the training and test datasets to compute the output of each sample in each set. Read the comments to understand what the function is doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LaU8dFudSAq"
      },
      "outputs": [],
      "source": [
        "def predict(model, train_data, test_data, batch_size):\n",
        "    train_images, train_yields, train_locations, train_indices, train_years = train_data\n",
        "\n",
        "    # Create a dataset of training samples\n",
        "    train_dataset = TensorDataset(\n",
        "        train_images, train_yields, train_locations, train_indices, train_years\n",
        "    )\n",
        "\n",
        "    test_images, test_yields, test_locations, test_indices, test_years = test_data\n",
        "\n",
        "    # Create a dataset of test samples\n",
        "    test_dataset = TensorDataset(\n",
        "        test_images, test_yields, test_locations, test_indices, test_years\n",
        "    )\n",
        "\n",
        "    # Create a train and test data loaders\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    results = defaultdict(list)\n",
        "\n",
        "    # Switch to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the training dataset\n",
        "        for train_im, train_yield, train_loc, train_idx, train_year in tqdm(\n",
        "            train_dataloader):\n",
        "            # Pass the sample to the model and compute the output\n",
        "            model_output = model(train_im.to(device))\n",
        "            pred = model_output\n",
        "\n",
        "            # Save the results\n",
        "            results[\"train_pred\"].extend(pred.squeeze(1).tolist())\n",
        "            results[\"train_real\"].extend(train_yield.squeeze(1).tolist())\n",
        "            results[\"train_loc\"].append(train_loc.numpy())\n",
        "            results[\"train_indices\"].append(train_idx.numpy())\n",
        "            results[\"train_years\"].extend(train_year.tolist())\n",
        "\n",
        "        # Iterate over the test dataset\n",
        "        for test_im, test_yield, test_loc, test_idx, test_year in tqdm(\n",
        "            test_dataloader\n",
        "        ):\n",
        "            # Compute the output\n",
        "            model_output = model(test_im.to(device))\n",
        "            pred = model_output\n",
        "\n",
        "            # Save the output\n",
        "            results[\"test_pred\"].extend(pred.squeeze(1).tolist())\n",
        "            results[\"test_real\"].extend(test_yield.squeeze(1).tolist())\n",
        "            results[\"test_loc\"].append(test_loc.numpy())\n",
        "            results[\"test_indices\"].append(test_idx.numpy())\n",
        "            results[\"test_years\"].extend(test_year.tolist())\n",
        "\n",
        "    for key in results:\n",
        "        if key in [\n",
        "            \"train_feat\",\n",
        "            \"test_feat\",\n",
        "            \"train_loc\",\n",
        "            \"test_loc\",\n",
        "            \"train_indices\",\n",
        "            \"test_indices\",\n",
        "            \"test_pred\",\n",
        "            \"test_real\",\n",
        "        ]:\n",
        "            results[key] = np.array(results[key])\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI73a8iDkYwB"
      },
      "source": [
        "## Running the Training and Evaluation\n",
        "Let's say we want to predict the yield for the year 2012. What we should do is train on data available for the years 2003 - 2011 and evaluate the model on the data for the year 2012. That way we can ensure we have trained a causal model (a model that has predictive power without seeing future data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq17dGmnWhpK"
      },
      "outputs": [],
      "source": [
        "def run_one_year(model, predict_year, time, train_steps, batch_size, lr):\n",
        "    # Use the data for years precedding `predict_year` as training data\n",
        "    train_idx = np.nonzero(years < predict_year)[0]\n",
        "    # Use the data for the year `predict_year` as evaluation (testing) data\n",
        "    test_idx = np.nonzero(years == predict_year)[0]\n",
        "\n",
        "    train_images, test_images = normalize_images(images[train_idx],\n",
        "                                                  images[test_idx])\n",
        "\n",
        "    # Return a training data tuple containing images, yields, locations, indices, and years\n",
        "    train_data = (\n",
        "        torch.as_tensor(\n",
        "                    train_images[:, :, :time, :], device=device\n",
        "                ).float(),\n",
        "        torch.as_tensor(yields[train_idx], device=device).float().unsqueeze(1),\n",
        "        torch.as_tensor(locations[train_idx]),\n",
        "        torch.as_tensor(indices[train_idx]),\n",
        "        torch.as_tensor(years[train_idx]),\n",
        "    )\n",
        "\n",
        "    # Return a test data tuple containing images, yields, locations, indices, and years\n",
        "    test_data = (\n",
        "            torch.as_tensor(\n",
        "                test_images[:, :, :time, :], device=device\n",
        "            ).float(),\n",
        "            torch.as_tensor(yields[test_idx], device=device).float().unsqueeze(1),\n",
        "            torch.as_tensor(locations[test_idx]),\n",
        "            torch.as_tensor(indices[test_idx]),\n",
        "            torch.as_tensor(years[test_idx]),\n",
        "    )\n",
        "\n",
        "    # Call the training function to train the model\n",
        "    train_scores, val_scores = train(model, train_data, train_steps, batch_size, lr)\n",
        "\n",
        "    # Call the evaluation function to evaluate the model on train and test sets\n",
        "    results = predict(model, train_data, test_data, batch_size)\n",
        "\n",
        "    model_information = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"val_loss\": val_scores[\"loss\"],\n",
        "            \"train_loss\": train_scores[\"loss\"],\n",
        "    }\n",
        "    for key in results:\n",
        "        model_information[key] = results[key]\n",
        "\n",
        "    true, pred =  model_information[\"test_real\"], model_information[\"test_pred\"]\n",
        "\n",
        "    # Compute the RMSE and ME\n",
        "    rmse = np.sqrt(np.mean((true - pred) ** 2))\n",
        "    me = np.mean(true - pred)\n",
        "\n",
        "    return rmse, me"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XVhY3DipmhE"
      },
      "source": [
        "## Running the Training/Evaluation\n",
        "We will now use the following function that uses the functions above to run the entire process of training.\n",
        "\n",
        "This function run training and evaluation of the model for each year in the variable `pred_years` defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeQmMuxJUbOM"
      },
      "outputs": [],
      "source": [
        "def run(model, batch_size=32, learning_rate=1e-3, weight_decay=0,\n",
        "        train_steps=2500):\n",
        "    years_list, run_numbers, rmse_list, me_list, times_list = [], [], [], [], []\n",
        "    times = [32]\n",
        "    for pred_year in pred_years:\n",
        "        for time in times:\n",
        "            results = run_one_year(model, pred_year, time, train_steps,\n",
        "                                   batch_size,learning_rate)\n",
        "            years_list.append(pred_year)\n",
        "            times_list.append(time)\n",
        "            rmse, me = results\n",
        "            rmse_list.append(rmse)\n",
        "            me_list.append(me)\n",
        "    data = {\n",
        "        \"year\": years_list,\n",
        "        \"time_idx\": times_list,\n",
        "        \"RMSE\": rmse_list,\n",
        "        \"ME\": me_list,\n",
        "    }\n",
        "    results_df = pd.DataFrame(data=data)\n",
        "    results_df.to_csv(\"results.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwc8BmFR4Wj3"
      },
      "source": [
        "## Question 7.2.2\n",
        "In the above function there are some hyperparameters that need to be put in the config. Find them and put them in the `config` dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEtkW65ghl_F"
      },
      "outputs": [],
      "source": [
        "model = ConvNet()\n",
        "model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA625KFS4T05"
      },
      "outputs": [],
      "source": [
        "run(model, train_steps=25000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMQyWOOmD4kg"
      },
      "outputs": [],
      "source": [
        "!python train.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
